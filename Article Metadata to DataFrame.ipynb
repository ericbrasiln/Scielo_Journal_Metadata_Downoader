{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Metadata to DataFrame\n",
    "\n",
    "This notebook presents the process of downloading the metadata from a list of journal articles and store it in a pandas.DataFrame object. First we need to import BeautifulSoup, os and Pandas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions explore the XML JATS file and store the information of some tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to extract information\n",
    "        \n",
    "def find_article_id():\n",
    "    article_id = soup.front.find(\"article-id\")\n",
    "    try:\n",
    "        return(article_id.string)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "def find_article_title():\n",
    "    article_title = soup.front.find(\"article-title\")\n",
    "    try:\n",
    "        return(article_title.string)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "def find_authors():\n",
    "    authors_lastnames = soup.front.find_all([\"surname\"])\n",
    "    authors_names = soup.front.find_all([\"given-names\"])\n",
    "    authors = []\n",
    "    try:\n",
    "        for author in range(len(authors_lastnames)):\n",
    "            authors.append(authors_names[author].string + \" \" + authors_lastnames[author].string)\n",
    "        return(\",\".join(authors))\n",
    "    except AttributeError:\n",
    "        return None\n",
    "  \n",
    "\n",
    "def find_pub_date():\n",
    "    day = soup.front.find(\"pub-date\").contents[1].string\n",
    "    month = soup.front.find(\"pub-date\").contents[3].string\n",
    "    year = soup.front.find(\"pub-date\").contents[5].string\n",
    "    date = [month, year]\n",
    "    try:\n",
    "        return('-'.join(date))\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "def find_volume():\n",
    "    volume = soup.front.find(\"volume\")\n",
    "    try:\n",
    "        return(volume.string)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "           \n",
    "def find_fpage():\n",
    "    fpage = soup.front.find(\"fpage\")\n",
    "    try:\n",
    "        return(fpage.string)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "def find_lpage():\n",
    "    lpage = soup.front.find(\"lpage\")\n",
    "    try:\n",
    "        return(lpage.string)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "def find_journal_title():\n",
    "    journal_title = soup.front.find(\"journal-title\")\n",
    "    try:\n",
    "        return(journal_title.string)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "def find_key_words():\n",
    "    key_words = soup.front.find_all(\"kwd\", lng=\"en\")\n",
    "    try:\n",
    "        key_words = [kwd.string for kwd in key_words] \n",
    "        return \", \".join(key_words)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "        \n",
    "\n",
    "    \n",
    "def find_abstract():\n",
    "    abstract_text = soup.front.find(\"abstract\")\n",
    "    try:\n",
    "        return(abstract_text.string)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "        \n",
    "          \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call the previous functions on each of the articles we have previously downloaded to create a dictionary with the data that we could then convert to a DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_dir = \"D:/journal_articles/xml_articles/\"\n",
    "txt_dir = \"D:/journal_articles/txt_articles/\"\n",
    "\n",
    "# Creates txt files in txt_dir for all articles in the xml_dir\n",
    "\n",
    "with os.scandir(xml_dir) as entries:\n",
    "    for entry in entries:\n",
    "        name = entry.name\n",
    "        name = name.replace('.xml', '.txt')\n",
    "        with open(entry, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "            soup = BeautifulSoup(file, \"lxml\")\n",
    "            elementos = soup.find(\"body\").find_all(\"p\")\n",
    "            text = []\n",
    "            for elem in elementos:\n",
    "                text.append(elem.text)\n",
    "                with open(txt_dir + name, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(\"\\n\".join(text))\n",
    "\n",
    "\n",
    "#From the xml_dir creates a DataFrame with articles meta-data\n",
    "\n",
    "file_name = []\n",
    "article_id = []\n",
    "authors = []\n",
    "article_title = []\n",
    "journal_title = []\n",
    "pub_date = []\n",
    "abstract = []\n",
    "key_words = []\n",
    "volume = [] \n",
    "fpage = [] \n",
    "lpage = []\n",
    "\n",
    "with os.scandir(xml_dir) as entries:\n",
    "    for entry in entries:\n",
    "        with open(entry, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "            soup = BeautifulSoup(file, \"html.parser\")\n",
    "            file_name.append(entry.name)\n",
    "            article_id.append(find_article_id())\n",
    "            authors.append(find_authors())\n",
    "            article_title.append(find_article_title())\n",
    "            journal_title.append(find_journal_title())\n",
    "            pub_date.append(find_pub_date())\n",
    "            abstract.append(find_abstract())\n",
    "            key_words.append(find_key_words())\n",
    "            volume.append(find_volume())\n",
    "            fpage.append(find_fpage())\n",
    "            lpage.append(find_lpage())\n",
    "\n",
    "\n",
    "\n",
    "data = {\"file_name\": file_name, \"article_id\": article_id, \"authors\":authors, \"article_title\": article_title, \"journal_title\": journal_title, \"pub_date\": pub_date, \"abstract\": abstract, \"key_words\": key_words, \"volume\": volume, \"fpage\": fpage, \"lpage\": lpage}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adds the paths to xml and txt files to the DataFrame\n",
    "\n",
    "def xml_file_path(name):\n",
    "    return(xml_dir + name)\n",
    "\n",
    "def txt_file_path(name):\n",
    "    return(txt_dir + name.replace('.xml', '.txt'))\n",
    "    \n",
    "xml_path = []\n",
    "txt_path = []\n",
    "\n",
    "\n",
    "for file in df[\"file_name\"]:\n",
    "    xml_path.append(xml_file_path(file))\n",
    "\n",
    "for name in df[\"file_name\"]:\n",
    "    txt_path.append(txt_file_path(name))\n",
    "    \n",
    "df[\"xml_path\"] = xml_path\n",
    "df[\"txt_path\"] = txt_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we store the DataFrame to a csv file to be able to acces it locally and do different queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/journal_articles/xml_articles/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "#Saves the DataFrame to a csv file in the xml_root directory\n",
    "\n",
    "csv_file = \"metadata.csv\"\n",
    "\n",
    "csv_file_path = (xml_dir + csv_file)\n",
    "\n",
    "df.to_csv(csv_file_path)\n",
    "\n",
    "print(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
